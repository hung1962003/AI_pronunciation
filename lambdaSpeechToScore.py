
import torch
import json
import os
import WordMatching as wm
import utilsFileIO
import pronunciationTrainer
import base64
import time
import audioread
import numpy as np
from torchaudio.transforms import Resample
import io
import tempfile
import function
import tempfile
import os
import subprocess
from pydub import AudioSegment
# import librosa
import numpy as np
# from scipy.signal import butter, lfilter
import soundfile as sf
trainer_SST_lambda = {}
trainer_SST_lambda['en'] = pronunciationTrainer.getTrainer("en")
trainer_SST_lambda['en-gb'] = pronunciationTrainer.getTrainer("en-gb")
transform = Resample(orig_freq=48000, new_freq=16000)


def lambda_handler(event, context):

    data = json.loads(event['body'])

    real_text = data['title']
    file_bytes = base64.b64decode(
        data['base64Audio'][22:].encode('utf-8'))
    language = data['language']

    if len(real_text) == 0:
        return {
            'statusCode': 200,
            'headers': {
                'Access-Control-Allow-Headers': '*',
                'Access-Control-Allow-Credentials': "true",
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
            },
            'body': ''
        }

    tmp_ogg = tempfile.NamedTemporaryFile(suffix=".ogg", delete=False)
    tmp_ogg_name = tmp_ogg.name
    tmp_ogg.write(file_bytes)
    tmp_ogg.flush()
    tmp_ogg.close()

    signal, fs = audioread_load(tmp_ogg_name)
    tmp_wav_path = tmp_ogg.name.replace(".ogg", ".wav")
  # üîπ D√πng ffmpeg ƒë·ªÉ convert .ogg -> .wav
    subprocess.run([
        "ffmpeg",
        "-i", tmp_ogg.name,   # ‚ö†Ô∏è ph·∫£i l√† .name (string path)
        "-ar", "16000",       # t·∫ßn s·ªë m·∫´u 16kHz
        "-ac", "1",           # √¢m thanh mono
        tmp_wav_path,
        "-y"                  # ghi ƒë√® n·∫øu file t·ªìn t·∫°i
    ],
    stdout=subprocess.DEVNULL,
    stderr=subprocess.DEVNULL,
    check=True  # ƒë·∫£m b·∫£o ffmpeg b√°o l·ªói n·∫øu th·∫•t b·∫°i
    )
    
    # üîπ L·ªçc t·∫°p √¢m tr∆∞·ªõc khi x·ª≠ l√Ω
    # print("üîß ƒêang l·ªçc t·∫°p √¢m...")
    # try:
    #     cleaned_audio, cleaned_sr = clean_voice(tmp_wav_path)
    #     # L∆∞u l·∫°i file ƒë√£ l·ªçc v√†o tmp_wav_path (ghi ƒë√®)
    #     sf.write(tmp_wav_path, cleaned_audio, cleaned_sr)
    #     # C·∫≠p nh·∫≠t signal t·ª´ file ƒë√£ l·ªçc ƒë·ªÉ ƒë·ªìng b·ªô
    #     signal = cleaned_audio
    #     fs = cleaned_sr
    #     print("‚úÖ ƒê√£ l·ªçc t·∫°p √¢m xong")
    # except Exception as e:
    #     print(f"‚ö†Ô∏è L·ªói khi l·ªçc t·∫°p √¢m: {e}, ti·∫øp t·ª•c v·ªõi file g·ªëc")
    #     # N·∫øu l·ªói, ti·∫øp t·ª•c v·ªõi file g·ªëc (signal v√† fs ƒë√£ c√≥ s·∫µn)
    
    try:
        print("üîç ƒêang g·ªçi model ƒë·ªÉ ch·∫•m ƒëi·ªÉm...")
        # ‚úÖ G·ªçi model x·ª≠ l√Ω t·ª´ ƒë∆∞·ªùng d·∫´n file .wav (ƒë√£ ƒë∆∞·ª£c l·ªçc t·∫°p √¢m)
        # Resample signal v·ªÅ 16kHz n·∫øu c·∫ßn (file ƒë√£ ƒë∆∞·ª£c convert v·ªÅ 16kHz b·∫±ng ffmpeg)
        if fs != 16000:
            signal_tensor = transform(torch.Tensor(signal)).unsqueeze(0)
        else:
            signal_tensor = torch.Tensor(signal).unsqueeze(0)
        result = trainer_SST_lambda[language].processAudioForGivenText(
            tmp_wav_path, signal_tensor, real_text, language
        )
    finally:
        # D·ªçn file t·∫°m .wav sau khi xong
        os.remove(tmp_wav_path)
        os.remove(tmp_ogg_name)

    start = time.time()
    real_transcripts_ipa = ' '.join(
        [word[0] for word in result['real_and_transcribed_words_ipa']])
    matched_transcripts_ipa = ' '.join(
        [word[1] for word in result['real_and_transcribed_words_ipa']])
    real_and_transcribed_words_ipa = result['real_and_transcribed_words_ipa']
    print(4)
    print(real_and_transcribed_words_ipa)
    real_transcripts = ' '.join(
        [word[0] for word in result['real_and_transcribed_words']])
    matched_transcripts = ' '.join(
        [word[1] for word in result['real_and_transcribed_words']])

    words_real = real_transcripts.lower().split()
    mapped_words = matched_transcripts.split()
    is_letter_correct_all_words = ''
    is_letter_correct_all_words = function.compare_ipa_pairs(
        real_and_transcribed_words_ipa,
        return_as_string=True,
        real_words=result['real_text']
    )

    total_letters, correct_letters, letters_accuracy_percent = calculate_letter_accuracy(
        is_letter_correct_all_words
    )

    
    # for idx, word_real in enumerate(words_real):

    #     mapped_letters, mapped_letters_indices = wm.get_best_mapped_words(
    #         mapped_words[idx], word_real)
    #     # is_letter_correct  =  wm.getWhichPhomenesWereTranscribedCorrectly(real_ipa,recorded_ipa)
    #     is_letter_correct = wm.getWhichLettersWereTranscribedCorrectly(
    #         word_real, mapped_letters)
    #     is_letter_correct_all_words += ''.join([str(is_correct)
    #                                             for is_correct in is_letter_correct]) + ' '
    print("Debug - is_letter_correct_all_words:", is_letter_correct_all_words)
    pair_accuracy_category = ' '.join(
        [str(category) for category in result['pronunciation_categories']])
    print('Time to post-process results: ', str(time.time()-start))
    
    res = {'real_transcript': result['recording_transcript'],
           'ipa_transcript': result['recording_ipa'],
           #'pronunciation_accuracy': str(int(result['pronunciation_accuracy'])),
           'pronunciation_accuracy': letters_accuracy_percent,
           'real_transcripts': real_transcripts, 'matched_transcripts': matched_transcripts,
           'real_transcripts_ipa': real_transcripts_ipa, 'matched_transcripts_ipa': matched_transcripts_ipa,
           'pair_accuracy_category': pair_accuracy_category,
           'start_time': result['start_time'],
           'end_time': result['end_time'],
           'is_letter_correct_all_words': is_letter_correct_all_words,
           'AIFeedback': result['AIFeedback']}
    print("Debug - result:", res)
    return json.dumps(res)



# T·∫°o b·ªô l·ªçc Butterworth
# def calculate_letter_accuracy(letter_string: str):
#     """Return total letters, correct letters, and accuracy percent from 1/0 string."""
#     if not letter_string:
#         return 0, 0, 0

#     segments = [segment for segment in letter_string.strip().split(' ') if segment]
#     total_letters = sum(len(segment) for segment in segments)
#     correct_letters = sum(segment.count('1') for segment in segments)

#     if total_letters == 0:
#         accuracy_percent = 0
#     else:
#         accuracy_percent = round((correct_letters / total_letters) * 100)

#     return total_letters, correct_letters, accuracy_percent


# def butter_filter(data, cutoff, sr, btype, order=4):
#     nyq = 0.5 * sr
#     normal_cutoff = cutoff / nyq
    
#     # ƒê·∫£m b·∫£o normal_cutoff n·∫±m trong kho·∫£ng h·ª£p l·ªá (0 < Wn < 1)
#     if normal_cutoff >= 1.0:
#         # N·∫øu cutoff >= Nyquist, gi·∫£m xu·ªëng 95% c·ªßa Nyquist ƒë·ªÉ an to√†n
#         normal_cutoff = 0.95
#     elif normal_cutoff <= 0:
#         # N·∫øu cutoff <= 0, ƒë·∫∑t gi√° tr·ªã t·ªëi thi·ªÉu
#         normal_cutoff = 0.01
    
#     b, a = butter(order, normal_cutoff, btype=btype)
#     return lfilter(b, a, data)

# L·ªçc t·∫°p √¢m n√¢ng cao
# def clean_voice(path):
#     """
#     L·ªçc t·∫°p √¢m t·ª´ file audio:
#     - High-pass filter ƒë·ªÉ gi·∫£m rung n·ªÅn
#     - Low-pass filter ƒë·ªÉ gi·∫£m hiss
#     - Noise gate ƒë·ªÉ lo·∫°i b·ªè t√≠n hi·ªáu y·∫øu
#     """
#     y, sr = librosa.load(path, sr=None)

#     # High-pass ƒë·ªÉ gi·∫£m rung n·ªÅn
#     y = butter_filter(y, 80, sr, "high")

#     # Low-pass ƒë·ªÉ gi·∫£m hiss (ƒë·∫£m b·∫£o cutoff < Nyquist frequency)
#     # V·ªõi sr=16kHz, Nyquist=8kHz, n√™n d√πng 7000 Hz ƒë·ªÉ an to√†n
#     lowpass_cutoff = min(7000, 0.9 * (sr / 2))
#     y = butter_filter(y, lowpass_cutoff, sr, "low")

#     # Noise gate: lo·∫°i b·ªè t√≠n hi·ªáu y·∫øu h∆°n ng∆∞·ª°ng
#     y = np.where(np.abs(y) < 0.015, 0, y)

#     return y, sr

def audioread_load(path, offset=0.0, duration=None, dtype=np.float32, text=None):
    """Load an audio buffer using audioread.

    This loads one block at a time, and then concatenates the results.
    """

    y = []
    with audioread.audio_open(path) as input_file:
        sr_native = input_file.samplerate
        n_channels = input_file.channels
        print(3)
        s_start = int(np.round(sr_native * offset)) * n_channels

        if duration is None:
            s_end = np.inf
        else:
            s_end = s_start + \
                (int(np.round(sr_native * duration)) * n_channels)

        n = 0

        for frame in input_file:
            frame = buf_to_float(frame, dtype=dtype)
            n_prev = n
            n = n + len(frame)

            if n < s_start:
                # offset is after the current frame
                # keep reading
                continue

            if s_end < n_prev:
                # we're off the end.  stop reading
                break

            if s_end < n:
                # the end is in this frame.  crop.
                frame = frame[: s_end - n_prev]

            if n_prev <= s_start <= n:
                # beginning is in this frame
                frame = frame[(s_start - n_prev):]

            # tack on the current frame
            y.append(frame)

    if y:
        y = np.concatenate(y)
        if n_channels > 1:
            y = y.reshape((-1, n_channels)).T
    else:
        y = np.empty(0, dtype=dtype)

        # üîπ N·∫øu c√≥ truy·ªÅn text => t·ª± ƒë·ªông ph√¢n t√≠ch stress
    # stress = None
    # if text is not None:
    #     print("üîç ƒêang ph√¢n t√≠ch tr·ªçng √¢m...")
    #     stress = detect_stress(y, sr_native, text)
    return y, sr_native

def buf_to_float(x, n_bytes=2, dtype=np.float32):
    """Convert an integer buffer to floating point values.
    This is primarily useful when loading integer-valued wav data
    into numpy arrays.

    Parameters
    ----------
    x : np.ndarray [dtype=int]
        The integer-valued data buffer

    n_bytes : int [1, 2, 4]
        The number of bytes per sample in ``x``

    dtype : numeric type
        The target output type (default: 32-bit float)

    Returns
    -------
    x_float : np.ndarray [dtype=float]
        The input data buffer cast to floating point
    """

    # Invert the scale of the data
    scale = 1.0 / float(1 << ((8 * n_bytes) - 1))

    # Construct the format string
    fmt = "<i{:d}".format(n_bytes)

    # Rescale and format the data buffer
    return scale * np.frombuffer(x, fmt).astype(dtype)
