
import dotenv

import json
import os

import wave
import base64
import requests
import io
import re

import phonemizer
from phonemizer.punctuation import Punctuation
from phonemizer.backend import EspeakBackend
from phonemizer.separator import Separator
from phonemizer.backend.espeak.wrapper import EspeakWrapper




import soundfile as sf
import ast
import random
import difflib
from gradio_client import Client, handle_file

import numpy as np
import torch
from typing import Union

from sequence_align.pairwise import hirschberg, needleman_wunsch
from phonemizer import phonemize
from groq import Groq
dotenv.load_dotenv()

# HF INFERENCE API
API_TOKEN = os.environ.get("HF_API_TOKEN") #https://huggingface.co/settings/profile
headers = {"Authorization": f"Bearer {API_TOKEN}"}
client1 = Groq(
    api_key=os.environ.get("GROQ_API_KEY"),
)
PHONEME_API_URL = "https://api-inference.huggingface.co/models/mrrubino/wav2vec2-large-xlsr-53-l2-arctic-phoneme" # "https://api-inference.huggingface.co/facebook/wav2vec2-xlsr-53-phon-cv-ft"
STT_API_URL = "https://api-inference.huggingface.co/models/openai/whisper-large-v3"


client = Client("lgtitony/doan")  # N·∫øu Space private: th√™m hf_token="hf_xxx"
EspeakWrapper.set_library('C:\Program Files\eSpeak NG\libespeak-ng.dll')
# def generate_reference_phoneme(reference_text, language='en'):
#     text = Punctuation(';:,.!"?()').remove(reference_text)
#     ref_words = [w.lower() for w in text.strip().split(' ') if w]

#     if language == 'en':
#         backend = EspeakBackend('en-us')
#     else:
#         backend = EspeakBackend('en-gb')

#     separator = Separator(phone='', word=None)
#     lexicon = []
#     for word in ref_words:
#         phoneme = backend.phonemize([word], separator=separator, strip=True)[0]
#         lexicon.append((word, phoneme))

#     reference_phoneme = ' '.join([phon for _, phon in lexicon])

#     return reference_phoneme
def convert_numpy(obj):
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, (list, tuple)):
        return [convert_numpy(x) for x in obj]
    elif isinstance(obj, dict):
        return {k: convert_numpy(v) for k, v in obj.items()}
    else:
        return obj
def getComparationPhonemes(reference_phoneme, recorded_phoneme):
    print("Reference Phoneme: ", reference_phoneme)
    print("Recorded Phoneme: ", recorded_phoneme)
    reference_phoneme = reference_phoneme.replace("Àà", "").replace("Àå", "")
    seq_a = reference_phoneme
    seq_b = list(recorded_phoneme.replace(' ',''))

    # recorded_phoneme['text']
    aligned_seq_a, aligned_seq_b = needleman_wunsch( # smith_waterman(
        seq_a,
        seq_b,
        match_score=1.0,
        mismatch_score=-1.0,
        indel_score=-1.0,
        gap="_",
    )

    aligned_reference_seq = ''.join(seq_a)
    aligned_recorded_seq = ''.join(aligned_seq_b)
    # recorded_sequence = "a…™_hoÀêp_√∞e…™_h…õv_ma…™_fiÀêv__r…ôdbr√¶nd_a…™l_biÀê_b√¶k_su_n__t ä_pliÀêz_w_iÀêdfoÀê__miÀê_"
    ref_start_positions = find_word_start_positions(''.join(aligned_reference_seq))

    # split recorded based on the reference start positions
    rec_split_words = split_recorded_sequence(''.join(aligned_recorded_seq), ref_start_positions)
    rec_split_words = [re.sub('( |\\_)$','',w) for w in rec_split_words]

    # split ref based on the reference start positions
    ref_split_words = split_recorded_sequence(''.join(aligned_reference_seq), ref_start_positions)
    ref_split_words = [re.sub('(\\_| )$','',w) for w in ref_split_words]

    # print('Reference Text: ',reference_text)
    # print('(word, reference_phoneme, recorded_phoneme)',list(zip(ref_words, ref_split_words, rec_split_words)))
    #word_comparision_list = list(zip(ref_words, ref_split_words, rec_split_words))
    word_comparision_list = list(zip(ref_split_words, rec_split_words))
    word_comparision_list
    return word_comparision_list
def ipa_to_english(ipa_text: str, english_words_list=None):
    # Handle case where english_words_list is a string
    if isinstance(english_words_list, str):
        english_words_list = english_words_list.split()
    
    # Handle case where english_words_list is None or empty
    if not english_words_list:
        return ""
    
    # Handle case where ipa_text is very short (single phoneme)
    if len(ipa_text.strip()) <= 2:
        print(f"Warning: Very short IPA text received: '{ipa_text}'")
        # Return the first word from english_words_list as fallback
        return english_words_list[0] if english_words_list else ""
    
    # S·ª≠ d·ª•ng separator h·ª£p l·ªá
    separator = Separator(phone='|', word=' ')  # kh√°c nhau gi·ªØa √¢m v·ªã v√† t·ª´
    phonemizer = EspeakBackend(language='en-us')

    ipa_map = {}
    for word in english_words_list:
        try:
            ipa = phonemizer.phonemize([word], separator=separator, strip=True)[0]
            ipa = ipa.replace('|', ' ')  # chuy·ªÉn v·ªÅ kho·∫£ng tr·∫Øng gi·ªØa √¢m v·ªã ƒë·ªÉ d·ªÖ so s√°nh
            ipa_map[word] = ipa
        except Exception as e:
            print(f"Error phonemizing word '{word}': {e}")
            continue

    ipa_tokens = ipa_text.strip().split()
    result_words = []

    for token in ipa_tokens:
        ipa_values = list(ipa_map.values())
        closest = difflib.get_close_matches(token, ipa_values, n=1, cutoff=0.75)
        if closest:
            for k, v in ipa_map.items():
                if v == closest[0]:
                    result_words.append(k)
                    break
        else:
            # If no close match found, try with lower cutoff
            closest = difflib.get_close_matches(token, ipa_values, n=1, cutoff=0.5)
            if closest:
                for k, v in ipa_map.items():
                    if v == closest[0]:
                        result_words.append(k)
                        break

    return " ".join(result_words)
def find_word_start_positions(reference_sequence):
    # Split the sequence into words based on spaces
    words = reference_sequence.split()
    # Initialize a list to store the start positions
    start_positions = []
    # Initialize the current position
    current_position = 0
    # Iterate over the words
    for word in words:
        # Add the current position to the start positions list
        start_positions.append(current_position)
        # Increment the current position by the length of the word plus 1 (for the space)
        current_position += len(word) + 1
    return start_positions
def split_recorded_sequence(recorded_sequence, start_positions):
    # Initialize a list to store the split words
    split_words = []
    # Iterate over the start positions
    for i in range(len(start_positions)):
        # Get the start position
        start = start_positions[i]
        # If it's the last word, get the end position as the length of the sequence
        if i == len(start_positions) - 1:
            end = len(recorded_sequence)
        # Otherwise, get the end position as the start position of the next word
        else:
            end = start_positions[i + 1]
        # Extract the word from the recorded sequence
        word = recorded_sequence[start:end]
        # Add the word to the list
        split_words.append(word)
    return split_words
def get_phonemes(filepath):
    print("‚è≥ ƒêang g·ª≠i file √¢m thanh ƒë·∫øn Hugging Face Space...")

    try:
        # G·ªçi h√†m predict (Gradio s·∫Ω t·ª± upload file qua handle_file)
        result = client.predict(
            audio_file=handle_file(filepath),  # ƒë√∫ng t√™n input c·ªßa Space (audio_file)
            api_name="/predict"                # ƒë√∫ng endpoint /predict theo View API
        )
        
        # Handle different result formats
        if isinstance(result, str):
            try:
                data = ast.literal_eval(result)
                text = data.get("text", "")
            except:
                text = result
        elif isinstance(result, dict):
            text = result.get("text", "")
        elif isinstance(result, list):
            text = result[0] if result else ""
        else:
            text = str(result)
        
        print("‚úÖ Nh·∫≠n k·∫øt qu·∫£ th√†nh c√¥ng!")
        print("üì¶ Raw result:", text)
        
        return text
        
    except Exception as e:
        print(f"Error getting phonemes: {e}")
        return ""
def align_real_and_transcribed(reference_sequence: str, recorded_sequence: str):
    ref_words = reference_sequence.split()
    rec_words = recorded_sequence.split()

    # T·∫°o ƒë·ªëi t∆∞·ª£ng so kh·ªõp
    matcher = difflib.SequenceMatcher(None, ref_words, rec_words)
    result = []

    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag == 'equal':
            for i in range(i2 - i1):
                result.append((ref_words[i1 + i], rec_words[j1 + i]))
        elif tag == 'replace':
            # thay th·∫ø => hai b√™n kh√°c nhau
            for i in range(max(i2 - i1, j2 - j1)):
                ref_word = ref_words[i1 + i] if i1 + i < len(ref_words) else '-'
                rec_word = rec_words[j1 + i] if j1 + i < len(rec_words) else '-'
                result.append((ref_word, rec_word))
        elif tag == 'delete':
            # b·ªã thi·∫øu b√™n record
            for i in range(i2 - i1):
                result.append((ref_words[i1 + i], '-'))
        elif tag == 'insert':
            # th√™m d∆∞ b√™n record
            for i in range(j2 - j1):
                result.append(('-', rec_words[j1 + i]))

    return result    
def aiFeedback(reference_text, word_comparision_list):
    system_message = """You are an expert dialect/accent coach for american spoken english. you will provide valuable feedback to improve my american accent. For ease of understanding, I would prefer you give suggestions for mipronunciation using google pronunciation respelling.
    provide following Overall Impression, Specific Feedback, Google Pronunciation Respelling Suggestions, additional tips"""
    chat_completion = client1.chat.completions.create(
        messages=[
                {
                    "role": "system",
                    "content": system_message
                },
                {
                    "role": "user",
                    "content": f"""Reference Text:  {reference_text}
        ( reference_phoneme, recorded_phoneme) 
        {word_comparision_list}""",
                }
        ],
        model="llama-3.3-70b-versatile",
        temperature=0
    )
    feedback = chat_completion.choices[0].message.content
    return feedback




def split_ipa_into_phonemes(ipa_string):
    """
    T√°ch IPA th√†nh c√°c phoneme ho√†n ch·ªânh, g·ªìm diphthong, ph·ª• √¢m gh√©p, v√† nguy√™n √¢m d√†i.
    """
    diphthongs = ['a…™', 'a ä', 'e…™', 'o…™', 'o ä', '…î…™', '…™…ô', ' ä…ô', 'e…ô']
    consonant_clusters = ['t É', 'd í']
    special_consonants = [' É', ' í', '≈ã', 'Œ∏', '√∞']
    
    ipa_clean = ipa_string.replace('_', '').replace(' ', '')
    if not ipa_clean:
        return []
    
    phonemes = []
    i = 0
    
    while i < len(ipa_clean):
        # 2 k√Ω t·ª± gh√©p (ph·ª• √¢m ho·∫∑c nguy√™n √¢m ƒë√¥i)
        if i + 1 < len(ipa_clean):
            two = ipa_clean[i:i+2]
            if two in diphthongs or two in consonant_clusters:
                phonemes.append(two)
                i += 2
                continue
        
        # Nguy√™n √¢m d√†i (vd: …úÀê, iÀê, uÀê, …îÀê)
        if i + 1 < len(ipa_clean) and ipa_clean[i+1] == 'Àê':
            phonemes.append(ipa_clean[i:i+2])
            i += 2
            continue
        
        # Ph·ª• √¢m ƒë·∫∑c bi·ªát
        if ipa_clean[i] in special_consonants:
            phonemes.append(ipa_clean[i])
            i += 1
            continue
        
        # C√≤n l·∫°i
        phonemes.append(ipa_clean[i])
        i += 1
    
    return phonemes

def split_ipa_into_syllables(ipa_string):
    """
    T√°ch IPA th√†nh c√°c √¢m ti·∫øt (syllables).
    M·ªôt √¢m ti·∫øt th∆∞·ªùng c√≥: ph·ª• √¢m ƒë·∫ßu (optional) + nguy√™n √¢m (required) + ph·ª• √¢m cu·ªëi (optional)
    """
    # ƒê·ªãnh nghƒ©a c√°c nguy√™n √¢m IPA (vowels)
    vowels = set('a√¶…ë…íe…ô…õi…™o…îu ä å…öÀê')
    
    # Lo·∫°i b·ªè underscore v√† spaces ƒë·ªÉ t√°ch
    ipa_clean = ipa_string.replace('_', '').replace(' ', '')
    if not ipa_clean:
        return []
    
    syllables = []
    current_syllable = []
    found_vowel = False
    
    i = 0
    while i < len(ipa_clean):
        char = ipa_clean[i]
        current_syllable.append(char)
        
        # Ki·ªÉm tra xem k√Ω t·ª± hi·ªán t·∫°i c√≥ ph·∫£i l√† nguy√™n √¢m kh√¥ng
        if char in vowels:
            found_vowel = True
        
        # N·∫øu ƒë√£ t√¨m th·∫•y nguy√™n √¢m v√† g·∫∑p ph·ª• √¢m m·ªõi (kh√¥ng ph·∫£i nguy√™n √¢m)
        # th√¨ c√≥ th·ªÉ l√† b·∫Øt ƒë·∫ßu √¢m ti·∫øt m·ªõi
        if found_vowel and char not in vowels:
            # Ki·ªÉm tra xem c√≥ nguy√™n √¢m ph√≠a sau kh√¥ng
            # N·∫øu c√≥, th√¨ k√Ω t·ª± hi·ªán t·∫°i thu·ªôc √¢m ti·∫øt ti·∫øp theo
            has_vowel_ahead = False
            for j in range(i + 1, len(ipa_clean)):
                if ipa_clean[j] in vowels:
                    has_vowel_ahead = True
                    break
                elif ipa_clean[j] not in vowels:
                    # N·∫øu g·∫∑p nhi·ªÅu ph·ª• √¢m li√™n ti·∫øp, d·ª´ng t√¨m
                    break
            
            if has_vowel_ahead:
                # K√Ω t·ª± hi·ªán t·∫°i thu·ªôc √¢m ti·∫øt ti·∫øp theo
                current_syllable.pop()  # B·ªè k√Ω t·ª± hi·ªán t·∫°i
                syllables.append(''.join(current_syllable))
                current_syllable = [char]
                found_vowel = False
        
        i += 1
    
    # Th√™m √¢m ti·∫øt cu·ªëi c√πng
    if current_syllable:
        syllables.append(''.join(current_syllable))
    print("syllables: ", syllables)
    return syllables if syllables else [ipa_clean]

def segment_word_into_graphemes(word: str):
	"""
	Chia t·ª´ ti·∫øng Anh th√†nh c√°c 'grapheme' (c·ª•m ch·ªØ) theo b·ªô quy t·∫Øc kh√≥a c·ª©ng.
	∆Øu ti√™n kh·ªõp d√†i nh·∫•t (longest-match) ƒë·ªÉ gom c√°c c·ª•m nh∆∞: tion, sion, io, ch, sh, th, ph, qu, ng, ee, oo, ea, ai, oi, oy, ay, au, aw, oa, ow, ew, ue, igh, tch, dge, ear, eer, ure...
	"""
	if not word:
		return []
	lowered = word.lower()
	# B·ªô grapheme nhi·ªÅu ch·ªØ (kh√≥a c·ª©ng 1 IPA ho·∫∑c vai tr√≤ ƒë∆°n v·ªã)
	locked_multi = [
		"tion","sion","tian","cian","ture","sure",
		"tch","dge","igh",
		"ch","sh","th","ph","ng","qu",
		"ee","oo","ea","ai","oi","oy","ay","au","aw","oa","ow","ew","ue","ie","ei",
		"io",  # v√≠ d·ª• trong pronunciation ‚Üí /…ô/
		"ear","eer","ure"
	]
	# S·∫Øp x·∫øp gi·∫£m d·∫ßn ƒë·ªô d√†i ƒë·ªÉ ∆∞u ti√™n kh·ªõp d√†i nh·∫•t
	locked_multi = sorted(locked_multi, key=len, reverse=True)
	graphemes = []
	i = 0
	while i < len(lowered):
		matched = None
		for pat in locked_multi:
			if lowered.startswith(pat, i):
				matched = word[i:i+len(pat)]
				break
		if matched:
			graphemes.append(matched)
			i += len(matched)
		else:
			graphemes.append(word[i])
			i += 1
	print("graphemes: ", graphemes)
	return graphemes

GRAPHEME_EXPECTED_PHONEMES = {
	"tion": 3,
	"sion": 3,
	"tian": 3,
	"cian": 3,
	"ture": 3,
	"sure": 3   ,
}

GRAPHEME_LETTER_TO_PHONEME_MAP = {
	"tion": [[0], [1], [1], [2]],   # t ‚Üí  É, i/o ‚Üí …ô, n ‚Üí n
	"sion": [[0], [1], [1], [2]],
	"tian": [[0], [1], [1], [2]],
	"cian": [[0], [1], [1], [2]],
	"ture": [[0], [1], [2], [2]],   # tu ‚Üí t É…ôr or similar
	"sure": [[0], [1], [2], [2]]
}

def grapheme_expected_phoneme_count(grapheme: str) -> int:
	"""
	∆Ø·ªõc l∆∞·ª£ng s·ªë IPA phoneme cho 1 grapheme.
	M·∫∑c ƒë·ªãnh 1. C√°c ngo·∫°i l·ªá ph·ªï bi·∫øn: 'x' ‚Üí /ks/ (2), 'qu' ‚Üí /kw/ (2).
	"""
	g = grapheme.lower()
	if g in GRAPHEME_EXPECTED_PHONEMES:
		return GRAPHEME_EXPECTED_PHONEMES[g]
	if g == "x":
		return 2
	if g == "qu":
		return 2
	return 1

def map_graphemes_to_phoneme_indices(graphemes, ipa_phonemes_count: int):
	"""
	Ph√¢n b·ªï index phoneme cho t·ª´ng grapheme theo th·ª© t·ª± tr√°i‚Üíph·∫£i d·ª±a tr√™n s·ªë l∆∞·ª£ng ∆∞·ªõc l∆∞·ª£ng.
	N·∫øu t·ªïng ∆∞·ªõc l∆∞·ª£ng != s·ªë phoneme th·∫≠t, s·∫Ω ƒëi·ªÅu ch·ªânh nh·∫π ƒë·ªÉ kh·ªõp t·ªïng:
	- N·∫øu thi·∫øu: d·ªìn ph·∫ßn thi·∫øu v√†o grapheme cu·ªëi.
	- N·∫øu th·ª´a: c·∫Øt b·ªõt ·ªü grapheme cu·ªëi c√πng nh∆∞ng v·∫´n t·ªëi thi·ªÉu 1 phoneme cho grapheme n·∫øu t·ªïng cho ph√©p.
	Tr·∫£ v·ªÅ list c√°c tuple (start_idx, end_idx_exclusive) cho m·ªói grapheme.
	"""
	est_counts = [max(1, grapheme_expected_phoneme_count(g)) for g in graphemes]
	total_est = sum(est_counts)
	# ƒêi·ªÅu ch·ªânh ƒë·ªÉ t·ªïng = ipa_phonemes_count
	if total_est < ipa_phonemes_count and len(est_counts) > 0:
		est_counts[-1] += (ipa_phonemes_count - total_est)
	elif total_est > ipa_phonemes_count and len(est_counts) > 0:
		over = total_est - ipa_phonemes_count
		# Gi·∫£m ·ªü cu·ªëi tr∆∞·ªõc, ƒë·∫£m b·∫£o >=1 n·∫øu c√≥ th·ªÉ
		for i in range(len(est_counts)-1, -1, -1):
			if over == 0:
				break
			can_reduce = est_counts[i] - 1
			if can_reduce > 0:
				reduce_by = min(can_reduce, over)
				est_counts[i] -= reduce_by
				over -= reduce_by
		# N·∫øu v·∫´n c√≤n over (tr∆∞·ªùng h·ª£p grapheme √≠t h∆°n phoneme), s·∫Ω c·∫Øt c·ª©ng ·ªü cu·ªëi
		if sum(est_counts) > ipa_phonemes_count:
			est_counts[-1] -= (sum(est_counts) - ipa_phonemes_count)
	# X√¢y mapping theo t√≠ch l≈©y
	# QUAN TR·ªåNG: ƒê·∫£m b·∫£o grapheme cu·ªëi lu√¥n ƒë∆∞·ª£c g√°n phoneme cu·ªëi
	mapping = []
	cursor = 0
	remaining_graphemes = len(est_counts)
	
	for idx, cnt in enumerate(est_counts):
		start = cursor
		remaining_graphemes -= 1
		
		# N·∫øu l√† grapheme cu·ªëi, ƒë·∫£m b·∫£o n√≥ ƒë∆∞·ª£c g√°n phoneme cu·ªëi
		if remaining_graphemes == 0:
			# Grapheme cu·ªëi lu√¥n ƒë∆∞·ª£c g√°n t·ª´ cursor ƒë·∫øn cu·ªëi
			end = ipa_phonemes_count
		else:
			# C√°c grapheme kh√°c: ph√¢n b·ªï b√¨nh th∆∞·ªùng
			# Nh∆∞ng ph·∫£i ƒë·ªÉ l·∫°i √≠t nh·∫•t 1 phoneme cho grapheme cu·ªëi
			max_available = ipa_phonemes_count - 1  # ƒê·ªÉ l·∫°i 1 cho grapheme cu·ªëi
			if max_available < 0:
				max_available = 0
			end = min(cursor + max(0, cnt), max_available)
			# N·∫øu kh√¥ng c√≥ phoneme m·ªõi, share v·ªõi grapheme tr∆∞·ªõc (n·∫øu c√≥)
			if end <= start:
				if cursor > 0:
					# Share phoneme v·ªõi grapheme tr∆∞·ªõc
					end = cursor
					start = cursor - 1
				elif cursor < max_available:
					end = cursor + 1
				else:
					# Kh√¥ng c√≥ phoneme n√†o, s·∫Ω ƒë∆∞·ª£c g√°n sau
					end = cursor
		
		mapping.append((start, end))
		cursor = end
		# N·∫øu ƒë√£ h·∫øt phoneme (tr·ª´ grapheme cu·ªëi), c√°c grapheme c√≤n l·∫°i share phoneme cu·ªëi
		if cursor >= ipa_phonemes_count - 1 and remaining_graphemes > 0:
			# C√°c grapheme c√≤n l·∫°i s·∫Ω share phoneme cu·ªëi v·ªõi grapheme cu·ªëi
			for _ in range(remaining_graphemes - 1):
				mapping.append((max(0, ipa_phonemes_count - 1), ipa_phonemes_count))
			break
	
	# ƒê·∫£m b·∫£o grapheme cu·ªëi lu√¥n ƒë∆∞·ª£c g√°n phoneme cu·ªëi (n·∫øu c√≥ phoneme)
	if mapping and ipa_phonemes_count > 0:
		last_start, last_end = mapping[-1]
		# Grapheme cu·ªëi ph·∫£i ƒë∆∞·ª£c g√°n √≠t nh·∫•t 1 phoneme (phoneme cu·ªëi)
		if last_end <= last_start or last_end < ipa_phonemes_count:
			mapping[-1] = (max(0, ipa_phonemes_count - 1), ipa_phonemes_count)
	
	return mapping

def compare_ipa_pairs(real_and_transcribed_words_ipa, strict_syllable_match: bool = False, return_as_string: bool = False, real_words = None):
    """
    So s√°nh IPA v√† tr·∫£ v·ªÅ k·∫øt qu·∫£.
    
    Args:
        real_and_transcribed_words_ipa: List of tuples (real_ipa, recorded_ipa)
        strict_syllable_match: N·∫øu True, ch·ªâ match trong c√πng syllable
        return_as_string: N·∫øu True, tr·∫£ v·ªÅ string thay v√¨ list
        real_words: List ho·∫∑c string c√°c t·ª´ ti·∫øng Anh t∆∞∆°ng ·ª©ng (ƒë·ªÉ map theo s·ªë ch·ªØ c√°i)
                   - N·∫øu l√† string: s·∫Ω t√°ch th√†nh list c√°c t·ª´
                   - N·∫øu l√† list: gi·ªØ nguy√™n
    """
    # X·ª≠ l√Ω real_words n·∫øu l√† string
    if isinstance(real_words, str):
        real_words = real_words.split()
    def ipa_compare(real_ipa, recorded_ipa, real_word=None):
        # T√°ch theo phoneme (nh·∫≠n di·ªán diphthong) thay v√¨ t·ª´ng k√Ω t·ª±
        ipa_units_real = split_ipa_into_phonemes(real_ipa)
        
        # Parse recorded IPA, keeping underscores for alignment tracking
        recorded_list = []
        for char in recorded_ipa:
            if char == '_':
                recorded_list.append('_')  # Keep underscore to mark gap
            elif char not in [' ', '\t']:  # Skip spaces
                recorded_list.append(char)
        
        # T√°ch recorded IPA th√†nh phoneme (b·ªè underscore khi t√°ch phoneme)
        recorded_clean = recorded_ipa.replace('_', '').replace(' ', '')
        recorded_phonemes_clean = split_ipa_into_phonemes(recorded_clean)
        
        # T√°ch theo √¢m ti·∫øt tr∆∞·ªõc ƒë·ªÉ so s√°nh
        real_syllables = split_ipa_into_syllables(real_ipa)
        recorded_syllables = split_ipa_into_syllables(recorded_ipa)
        
        # T·∫°o ipa_units_recorded t·ª´ recorded_phonemes_clean v·ªõi underscore
        # Map t·ª´ character list sang phoneme list
        ipa_units_recorded = []
        recorded_phoneme_idx = 0
        
        i = 0
        while i < len(recorded_list):
            if recorded_list[i] == '_':
                ipa_units_recorded.append('_')
                i += 1
            else:
                # T√¨m phoneme ch·ª©a k√Ω t·ª± n√†y
                if recorded_phoneme_idx < len(recorded_phonemes_clean):
                    phoneme = recorded_phonemes_clean[recorded_phoneme_idx]
                    # Ki·ªÉm tra xem k√Ω t·ª± hi·ªán t·∫°i c√≥ ph·∫£i l√† k√Ω t·ª± ƒë·∫ßu c·ªßa phoneme n√†y kh√¥ng
                    if recorded_list[i] == phoneme[0]:
                        ipa_units_recorded.append(phoneme)
                        # B·ªè qua c√°c k√Ω t·ª± c√≤n l·∫°i c·ªßa phoneme n√†y (tr·ª´ underscore)
                        chars_consumed = 0
                        for j in range(i + 1, min(i + len(phoneme), len(recorded_list))):
                            if recorded_list[j] == '_':
                                break
                            if j < len(phoneme) and recorded_list[j] == phoneme[j - i]:
                                chars_consumed += 1
                            else:
                                break
                        i += chars_consumed + 1
                        recorded_phoneme_idx += 1
                    else:
                        # K√Ω t·ª± kh√¥ng kh·ªõp v·ªõi phoneme hi·ªán t·∫°i, th·ª≠ t√¨m phoneme kh√°c
                        # Ho·∫∑c ƒë∆°n gi·∫£n l√† m·ªôt k√Ω t·ª± ƒë∆°n
                        found_phoneme = False
                        for ph_idx, ph in enumerate(recorded_phonemes_clean):
                            if recorded_list[i] == ph[0] and ph_idx >= recorded_phoneme_idx:
                                # N·∫øu c√≥ phoneme kh√°c b·∫Øt ƒë·∫ßu b·∫±ng k√Ω t·ª± n√†y
                                ipa_units_recorded.append(ph)
                                chars_consumed = 0
                                for j in range(i + 1, min(i + len(ph), len(recorded_list))):
                                    if recorded_list[j] == '_':
                                        break
                                    if j - i < len(ph) and recorded_list[j] == ph[j - i]:
                                        chars_consumed += 1
                                    else:
                                        break
                                i += chars_consumed + 1
                                recorded_phoneme_idx = ph_idx + 1
                                found_phoneme = True
                                break
                        
                        if not found_phoneme:
                            # K√Ω t·ª± ƒë∆°n, kh√¥ng thu·ªôc phoneme n√†o
                            ipa_units_recorded.append(recorded_list[i])
                            i += 1
                else:
                    # Kh√¥ng c√≤n phoneme n√†o, th√™m k√Ω t·ª± ƒë∆°n
                    ipa_units_recorded.append(recorded_list[i])
                    i += 1
        
        # T·∫°o mapping: m·ªói phoneme trong real IPA thu·ªôc √¢m ti·∫øt n√†o
        # C·∫ßn map t·ª´ phoneme list sang syllable
        phoneme_to_syllable = {}
        phoneme_idx = 0
        for syl_idx, syllable in enumerate(real_syllables):
            # T√°ch syllable th√†nh phoneme ƒë·ªÉ ƒë·∫øm
            syl_phonemes = split_ipa_into_phonemes(syllable)
            for i in range(len(syl_phonemes)):
                if phoneme_idx < len(ipa_units_real):
                    phoneme_to_syllable[phoneme_idx] = syl_idx
                    phoneme_idx += 1
        
        # So s√°nh t·ª´ng √¢m ti·∫øt v·ªõi recorded
        syllable_results = {}
        recorded_syl_used = [False] * len(recorded_syllables)
        
        for syl_idx, real_syllable in enumerate(real_syllables):
            # T√°ch real syllable th√†nh phoneme
            real_syl_phonemes = split_ipa_into_phonemes(real_syllable)
            
            # ∆Øu ti√™n match theo th·ª© t·ª±: syllable 1 v·ªõi syllable 1, syllable 2 v·ªõi syllable 2, ...
            # Ch·ªâ khi kh√¥ng match ·ªü ƒë√∫ng v·ªã tr√≠ m·ªõi t√¨m ·ªü v·ªã tr√≠ kh√°c
            best_match_idx = None
            best_match_score = 0
            
            # ƒê·∫ßu ti√™n, th·ª≠ match v·ªõi recorded syllable ·ªü c√πng v·ªã tr√≠
            if syl_idx < len(recorded_syllables) and not recorded_syl_used[syl_idx]:
                recorded_syllable = recorded_syllables[syl_idx]
                recorded_syl_phonemes = split_ipa_into_phonemes(recorded_syllable)
                
                # So s√°nh √¢m ti·∫øt: ƒë·∫øm s·ªë phoneme gi·ªëng nhau ·ªü ƒë√∫ng v·ªã tr√≠
                match_count = 0
                min_len = min(len(real_syl_phonemes), len(recorded_syl_phonemes))
                for i in range(min_len):
                    if real_syl_phonemes[i] == recorded_syl_phonemes[i]:
                        match_count += 1
                
                if match_count > 0:
                    best_match_score = match_count
                    best_match_idx = syl_idx
            
            # N·∫øu kh√¥ng match ·ªü ƒë√∫ng v·ªã tr√≠, t√¨m ·ªü v·ªã tr√≠ kh√°c
            if best_match_idx is None:
                for rec_syl_idx, recorded_syllable in enumerate(recorded_syllables):
                    if recorded_syl_used[rec_syl_idx]:
                        continue
                    
                    # T√°ch recorded syllable th√†nh phoneme
                    recorded_syl_phonemes = split_ipa_into_phonemes(recorded_syllable)
                    
                    # So s√°nh √¢m ti·∫øt: ƒë·∫øm s·ªë phoneme gi·ªëng nhau (theo th·ª© t·ª±)
                    match_count = 0
                    min_len = min(len(real_syl_phonemes), len(recorded_syl_phonemes))
                    for i in range(min_len):
                        if real_syl_phonemes[i] == recorded_syl_phonemes[i]:
                            match_count += 1
                    
                    if match_count > best_match_score:
                        best_match_score = match_count
                        best_match_idx = rec_syl_idx
            
            # N·∫øu t√¨m th·∫•y match t·ªët, ƒë√°nh d·∫•u ƒë√£ d√πng
            if best_match_idx is not None and best_match_score > 0:
                syllable_results[syl_idx] = best_match_idx
                recorded_syl_used[best_match_idx] = True
        
        # So s√°nh t·ª´ng phoneme: n·∫øu √¢m ti·∫øt match, so s√°nh phoneme trong √¢m ti·∫øt ƒë√≥
        result = []
        recorded_phoneme_idx = 0
        
        for real_idx, real_phoneme in enumerate(ipa_units_real):
            syl_idx = phoneme_to_syllable.get(real_idx, -1)
            found_match = False
            
            # N·∫øu √¢m ti·∫øt n√†y c√≥ match trong recorded, so s√°nh phoneme c·ª• th·ªÉ
            if syl_idx in syllable_results:
                rec_syl_idx = syllable_results[syl_idx]
                real_syllable = real_syllables[syl_idx]
                recorded_syllable = recorded_syllables[rec_syl_idx]
                
                # T√°ch th√†nh phoneme ƒë·ªÉ so s√°nh
                real_syl_phonemes = split_ipa_into_phonemes(real_syllable)
                recorded_syl_phonemes = split_ipa_into_phonemes(recorded_syllable)
                
                # T√¨m v·ªã tr√≠ c·ªßa phoneme n√†y trong √¢m ti·∫øt real
                real_syl_start = sum(len(split_ipa_into_phonemes(real_syllables[i])) for i in range(syl_idx))
                offset_in_syl = real_idx - real_syl_start
                
                # So s√°nh v·ªõi phoneme t∆∞∆°ng ·ª©ng trong recorded syllable
                # CH·ªà match ·ªü ƒë√∫ng v·ªã tr√≠ offset, kh√¥ng t√¨m t·ª´ v·ªã tr√≠ sau
                # ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o th·ª© t·ª± ch√≠nh x√°c: m·ªói phoneme ph·∫£i match ·ªü ƒë√∫ng v·ªã tr√≠
                if offset_in_syl < len(recorded_syl_phonemes):
                    recorded_phoneme = recorded_syl_phonemes[offset_in_syl]
                    if recorded_phoneme == real_phoneme:
                        result.append('1')
                        found_match = True
                        # C·∫≠p nh·∫≠t recorded_phoneme_idx ƒë·ªÉ tr√°nh match l·∫°i phoneme ƒë√£ d√πng
                        # T√¨m v·ªã tr√≠ c·ªßa phoneme n√†y trong ipa_units_recorded (b·ªè qua underscore)
                        # T√≠nh v·ªã tr√≠ b·∫Øt ƒë·∫ßu c·ªßa recorded syllable trong ipa_units_recorded (kh√¥ng t√≠nh underscore)
                        recorded_syl_start_in_units = 0
                        for prev_syl_idx in range(rec_syl_idx):
                            prev_recorded_syl = recorded_syllables[prev_syl_idx]
                            prev_recorded_syl_phonemes = split_ipa_into_phonemes(prev_recorded_syl)
                            recorded_syl_start_in_units += len(prev_recorded_syl_phonemes)
                        recorded_phoneme_pos_in_units = recorded_syl_start_in_units + offset_in_syl
                        # T√¨m v·ªã tr√≠ th·ª±c t·∫ø trong ipa_units_recorded (b·ªè qua underscore)
                        actual_pos = 0
                        non_underscore_count = 0
                        for idx, unit in enumerate(ipa_units_recorded):
                            if unit != '_':
                                if non_underscore_count == recorded_phoneme_pos_in_units:
                                    actual_pos = idx
                                    break
                                non_underscore_count += 1
                        if actual_pos < len(ipa_units_recorded):
                            recorded_phoneme_idx = actual_pos + 1
                    # N·∫øu kh√¥ng match ·ªü ƒë√∫ng v·ªã tr√≠, kh√¥ng t√¨m ·ªü v·ªã tr√≠ kh√°c
                    # ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o: n·∫øu phoneme sai ·ªü v·ªã tr√≠ ƒë√≥, ph·∫£i l√† '0'
                    # C·∫≠p nh·∫≠t recorded_phoneme_idx ƒë·ªÉ b·ªè qua phoneme ·ªü v·ªã tr√≠ offset
                    if not found_match:
                        recorded_syl_start_in_units = 0
                        for prev_syl_idx in range(rec_syl_idx):
                            prev_recorded_syl = recorded_syllables[prev_syl_idx]
                            prev_recorded_syl_phonemes = split_ipa_into_phonemes(prev_recorded_syl)
                            recorded_syl_start_in_units += len(prev_recorded_syl_phonemes)
                        recorded_phoneme_pos_in_units = recorded_syl_start_in_units + offset_in_syl
                        # T√¨m v·ªã tr√≠ th·ª±c t·∫ø trong ipa_units_recorded (b·ªè qua underscore)
                        actual_pos = 0
                        non_underscore_count = 0
                        for idx, unit in enumerate(ipa_units_recorded):
                            if unit != '_':
                                if non_underscore_count == recorded_phoneme_pos_in_units:
                                    actual_pos = idx
                                    break
                                non_underscore_count += 1
                        if actual_pos < len(ipa_units_recorded):
                            # Ch·ªâ c·∫≠p nh·∫≠t n·∫øu recorded_phoneme_idx ch∆∞a v∆∞·ª£t qu√° v·ªã tr√≠ n√†y
                            if recorded_phoneme_idx <= actual_pos:
                                recorded_phoneme_idx = actual_pos + 1
            
            # KH√îNG cho ph√©p fallback match t·ª´ v·ªã tr√≠ xa
            # N·∫øu kh√¥ng match trong syllable, ph·∫£i l√† '0'
            # ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o t√≠nh ch√≠nh x√°c: m·ªói phoneme ch·ªâ match trong syllable t∆∞∆°ng ·ª©ng
            if not found_match:
                result.append('0')
                # Khi kh√¥ng match trong syllable, v·∫´n c·∫ßn c·∫≠p nh·∫≠t recorded_phoneme_idx
                # ƒë·ªÉ b·ªè qua phoneme t∆∞∆°ng ·ª©ng trong recorded v√† ti·∫øp t·ª•c v·ªõi phoneme ti·∫øp theo
                if syl_idx in syllable_results:
                    rec_syl_idx = syllable_results[syl_idx]
                    recorded_syllable = recorded_syllables[rec_syl_idx]
                    recorded_syl_phonemes = split_ipa_into_phonemes(recorded_syllable)
                    real_syl_start = sum(len(split_ipa_into_phonemes(real_syllables[i])) for i in range(syl_idx))
                    offset_in_syl = real_idx - real_syl_start
                    # N·∫øu offset h·ª£p l·ªá v√† ch∆∞a v∆∞·ª£t qu√° recorded syllable, tƒÉng recorded_phoneme_idx
                    # ƒë·ªÉ b·ªè qua phoneme ·ªü v·ªã tr√≠ offset trong recorded syllable
                    if offset_in_syl < len(recorded_syl_phonemes):
                        recorded_syl_start_in_units = 0
                        for prev_syl_idx in range(rec_syl_idx):
                            prev_recorded_syl = recorded_syllables[prev_syl_idx]
                            prev_recorded_syl_phonemes = split_ipa_into_phonemes(prev_recorded_syl)
                            recorded_syl_start_in_units += len(prev_recorded_syl_phonemes)
                        recorded_phoneme_pos_in_units = recorded_syl_start_in_units + offset_in_syl
                        # T√¨m v·ªã tr√≠ th·ª±c t·∫ø trong ipa_units_recorded (b·ªè qua underscore)
                        actual_pos = 0
                        non_underscore_count = 0
                        for idx, unit in enumerate(ipa_units_recorded):
                            if unit != '_':
                                if non_underscore_count == recorded_phoneme_pos_in_units:
                                    actual_pos = idx
                                    break
                                non_underscore_count += 1
                        if actual_pos < len(ipa_units_recorded):
                            # Lu√¥n tƒÉng ƒë·ªÉ b·ªè qua phoneme n√†y trong recorded
                            recorded_phoneme_idx = actual_pos + 1
		
        # N·∫øu c√≥ real_word, map t·ª´ phoneme sang ch·ªØ c√°i theo grapheme
        if real_word:
            phoneme_result = list(result)        # list c√°c '1'/'0' cho m·ªói phoneme chu·∫©n
            ipa_phoneme_count = len(ipa_units_real)
            graphemes = segment_word_into_graphemes(real_word)
            # Map grapheme ‚Üí d·∫£i index phoneme
            ranges = map_graphemes_to_phoneme_indices(graphemes, ipa_phoneme_count)
            # N·∫øu mapping b·∫•t h·ª£p l·ªá v·ªÅ k√≠ch th∆∞·ªõc, fallback heuristic c≈©
            if len(ranges) != len(graphemes):
                # Fallback: gi·ªØ nguy√™n logic c≈© n·∫øu c√≥ tr·ª•c tr·∫∑c
                letter_result = []
                if len(real_word) == len(phoneme_result):
                    letter_result = phoneme_result
                elif len(real_word) > len(phoneme_result):
                    if len(phoneme_result) == 1:
                        letter_result = [phoneme_result[0]] * len(real_word)
                    else:
                        letter_result.append(phoneme_result[0])
                        middle_letters = len(real_word) - 2
                        middle_phonemes = len(phoneme_result) - 2
                        if middle_letters > 0 and middle_phonemes > 0:
                            for i in range(1, len(real_word) - 1):
                                letter_pos_in_middle = i - 1
                                ph_idx = 1 + int(letter_pos_in_middle * middle_phonemes / middle_letters)
                                if ph_idx >= len(phoneme_result) - 1:
                                    ph_idx = len(phoneme_result) - 2
                                letter_result.append(phoneme_result[ph_idx])
                        elif middle_letters > 0:
                            for i in range(1, len(real_word) - 1):
                                if i == len(real_word) - 2:
                                    letter_result.append(phoneme_result[-1])
                                else:
                                    letter_result.append('0')
                        letter_result.append(phoneme_result[-1])
                else:
                    ratio = len(phoneme_result) / len(real_word)
                    for i in range(len(real_word)):
                        start_idx = int(i * ratio)
                        end_idx = int((i + 1) * ratio)
                        if start_idx < len(phoneme_result):
                            if any(phoneme_result[j] == '1' for j in range(start_idx, min(end_idx, len(phoneme_result)))):
                                letter_result.append('1')
                            else:
                                letter_result.append('0')
                        else:
                            letter_result.append('0')
                return ''.join(letter_result)
            # T·∫°o k·∫øt qu·∫£ theo quy t·∫Øc:
            # - Grapheme 1 ch·ªØ, 1 phoneme ‚Üí d√πng tr·ª±c ti·∫øp
            # - Grapheme nhi·ªÅu ch·ªØ, 1 phoneme ‚Üí nh√¢n k·∫øt qu·∫£ ra s·ªë ch·ªØ (vd 'io'‚Üí m·ªôt IPA, sai ‚Üí '00')
            # - Grapheme 1 ch·ªØ, nhi·ªÅu phoneme ‚Üí t·∫•t c·∫£ ph·∫£i ƒë√∫ng m·ªõi l√† '1', n·∫øu c√≥ 1 sai ‚Üí '0'
            # - Grapheme nhi·ªÅu ch·ªØ, nhi·ªÅu phoneme ‚Üí t·∫•t c·∫£ phoneme c·ªßa grapheme ph·∫£i ƒë√∫ng; nh√¢n ra theo s·ªë ch·ªØ
            letter_result = []
            for g, (start, end) in zip(graphemes, ranges):
                assigned = phoneme_result[start:end] if start < end else []
                g_lower = g.lower()
                if g_lower in GRAPHEME_LETTER_TO_PHONEME_MAP and assigned:
                    per_letter_idx = GRAPHEME_LETTER_TO_PHONEME_MAP[g_lower]
                    # ƒêi·ªÅu ch·ªânh n·∫øu mapping kh√¥ng kh·ªõp ƒë·ªô d√†i
                    if len(per_letter_idx) != len(g):
                        per_letter_idx = per_letter_idx[:len(g)]
                        if len(per_letter_idx) < len(g):
                            per_letter_idx.extend([[len(assigned)-1]] * (len(g) - len(per_letter_idx)))
                    for idxs in per_letter_idx:
                        # idxs l√† list index phoneme t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ
                        if not idxs:
                            letter_result.append('0')
                            continue
                        values = []
                        for ix in idxs:
                            if 0 <= ix < len(assigned):
                                values.append(assigned[ix])
                        letter_result.append('1' if values and all(v == '1' for v in values) else '0')
                else:
                    # N·∫øu kh√¥ng c√≥ mapping c·ª• th·ªÉ
                    if not assigned:
                        g_scores = ['0'] * len(g)
                    elif len(assigned) == 1:
                        g_scores = [assigned[0]] * len(g)
                    else:
                        # Ph√¢n b·ªë ƒë·ªÅu phoneme cho ch·ªØ
                        g_scores = []
                        total_phonemes = len(assigned)
                        for letter_idx in range(len(g)):
                            start_idx = (letter_idx * total_phonemes) // len(g)
                            end_idx = ((letter_idx + 1) * total_phonemes) // len(g)
                            if end_idx <= start_idx:
                                end_idx = start_idx + 1 if start_idx < total_phonemes else total_phonemes
                            segment = assigned[start_idx:end_idx]
                            g_scores.append('1' if segment and all(x == '1' for x in segment) else '0')
                    letter_result.extend(g_scores)
            # N·∫øu v√¨ ƒëi·ªÅu ch·ªânh mapping khi·∫øn s·ªë ch·ªØ ‚â† ƒë·ªô d√†i th·∫≠t c·ªßa t·ª´ (hi·∫øm), c·∫Øt/ƒë·ªám cho kh·ªõp
            if len(letter_result) > len(real_word):
                letter_result = letter_result[:len(real_word)]
            elif len(letter_result) < len(real_word):
                letter_result.extend(['0'] * (len(real_word) - len(letter_result)))
            return ''.join(letter_result)

        return ''.join(result)

    results = []
    for idx, (real, recorded) in enumerate(real_and_transcribed_words_ipa):
        # L·∫•y t·ª´ t∆∞∆°ng ·ª©ng t·ª´ real_words
        real_word = None
        if real_words:
            if isinstance(real_words, list) and idx < len(real_words):
                real_word = real_words[idx]
            elif isinstance(real_words, str):
                # N·∫øu l√† string, t√°ch v√† l·∫•y t·ª´ t∆∞∆°ng ·ª©ng
                words_list = real_words.split()
                if idx < len(words_list):
                    real_word = words_list[idx]
        results.append(ipa_compare(real, recorded, real_word))

    if return_as_string:
        return ' '.join(results)
    return results
